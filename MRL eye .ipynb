{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory = r\"C:\\Users\\Aditya Venkatesh\\Drowsiness detection new\\archive (6)\\mrleyedataset\"\n",
    "Classes = [\"Close-Eyes\", \"Open-Eyes\"]\n",
    "for category in Classes:\n",
    "    path = os.path.join(Datadirectory, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        backtorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "        plt.imshow(img_array, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee597f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 24\n",
    "new_array = cv2.resize(backtorgb, (img_size, img_size))\n",
    "plt.imshow(new_array, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Data = []\n",
    "def create_training_Data():\n",
    "   for category in Classes:\n",
    "       path = os.path.join(Datadirectory, category)\n",
    "       class_num = Classes.index(category) # 0 1,\n",
    "       for img in os.listdir(path):\n",
    "           try:\n",
    "               img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "               backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)\n",
    "               new_array = cv2.resize(backtorgb, (img_size, img_size))\n",
    "               training_Data.append([new_array,class_num])\n",
    "           except Exception as e:\n",
    "               pass\n",
    "create_training_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for features,label in training_Data:\n",
    "  X.append(features)\n",
    "  y.append(label)\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad007de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X and y to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce09a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ebd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
    "\n",
    "model.save('Mymodel.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07532963",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "new_model = load_model(r\"C:\\Users\\Aditya Venkatesh\\Downloads\\Drowsiness detection\\Drowsiness detection\\models\\cnnCat2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[\"Close_eye\",\"Open_eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize sound mixer\n",
    "winsound.PlaySound(None, winsound.SND_PURGE)\n",
    "frequency = 2500  # Set frequency to 2500\n",
    "duration = 1500  # Set duration to 1500 ms == 1.5 sec\n",
    "\n",
    "# Load Haar cascade classifiers for face and eye detection\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eyeCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Start capturing video from webcam\n",
    "\n",
    "# Check if webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "#cap.set(cv2.CAP_PROP_FPS, 5)  # Set FPS of video capture\n",
    "\n",
    "counter = 0  # Counter to track consecutive frames with closed eyes\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Read frame from video feed\n",
    "        \n",
    "        # Check if frame is None (failed to capture)\n",
    "        if frame is None:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            continue\n",
    "\n",
    "        # Convert frame to grayscale for face and eye detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces in the frame\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "        \n",
    "        # Loop through detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw rectangle around face\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Extract region of interest (ROI) for eyes\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Detect eyes within the face ROI\n",
    "            eyes = eyeCascade.detectMultiScale(roi_gray)\n",
    "            \n",
    "            # Loop through detected eyes\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                # Draw rectangle around eyes\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255, 0, 0), 2)\n",
    "                \n",
    "                # Extract region of interest (ROI) for each eye\n",
    "                eye_roi = roi_gray[ey:ey+eh, ex:ex+ew]\n",
    "                \n",
    "                # Preprocess eye image for prediction\n",
    "                eye_image = cv2.resize(eye_roi, (24, 24))\n",
    "                eye_image = eye_image.reshape(24,24,-1)\n",
    "                eye_image = np.expand_dims(eye_image, axis=0)\n",
    "                eye_image = eye_image / 255.0\n",
    "                \n",
    "                # Make prediction using the model\n",
    "                predictions = new_model.predict(eye_image)\n",
    "                print(predictions)\n",
    "                index=np.argmax(predictions[0])\n",
    "                prediction_class= label[np.argmax(predictions[0])]\n",
    "                \n",
    "                # Determine if eyes are closed based on prediction\n",
    "                if index == 1:\n",
    "                    status = \"Open-Eyes\"\n",
    "                    counter = 0  # Reset counter if eyes are open\n",
    "                else:\n",
    "                    status = \"Close-Eyes\"\n",
    "                    counter += 1  # Increment counter if eyes are closed\n",
    "                    \n",
    "                    # Alert if eyes remain closed for consecutive frames\n",
    "                    if counter > 10:\n",
    "                        status = \"Drowsiness Detected!\"\n",
    "                        winsound.Beep(frequency, duration)  # Sound alert\n",
    "                        counter = 0  # Reset counter after alert\n",
    "                        \n",
    "                # Display status text\n",
    "                cv2.putText(frame, status, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Display frame with annotations using Matplotlib\n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Drowsiness Detection')\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.show()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Keyboard Interrupt. Exiting...\")\n",
    "finally:\n",
    "    # Release video capture and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3589b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b7c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
